# DSPy Code Configuration Example
# This file shows all available configuration options for DSPy Code
# Copy sections you need to your dspy_config.yaml file

# ============================================================================
# PROJECT INFORMATION
# ============================================================================
name: my-dspy-project
version: 0.1.0
dspy_version: 2.4.0

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================
# Directory where generated DSPy components will be saved
output_directory: generated

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
# Configure language models for DSPy programs
# You can use local models (Ollama) or cloud providers (OpenAI, Anthropic, Gemini)

models:
  # --- Ollama (Local Models) ---
  # Free, private, runs on your machine
  ollama_endpoint: http://localhost:11434
  ollama_models:
    - llama2
    - mistral
    - codellama

  # --- OpenAI ---
  # Requires API key from https://platform.openai.com/api-keys
  # RECOMMENDED: Set OPENAI_API_KEY environment variable or in .env file
  # DO NOT commit API keys to version control!
  openai_api_key: null  # Leave as null to use environment variable OPENAI_API_KEY
  openai_model: gpt-4  # Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo

  # --- Anthropic Claude ---
  # Requires API key from https://console.anthropic.com/
  # RECOMMENDED: Set ANTHROPIC_API_KEY environment variable or in .env file
  anthropic_api_key: null  # Leave as null to use environment variable ANTHROPIC_API_KEY
  anthropic_model: claude-3-sonnet-20240229  # Options: claude-3-opus, claude-3-sonnet, claude-3-haiku

  # --- Google Gemini ---
  # Requires API key from https://makersuite.google.com/app/apikey
  # RECOMMENDED: Set GEMINI_API_KEY or GOOGLE_API_KEY environment variable or in .env file
  gemini_api_key: null  # Leave as null to use environment variable GEMINI_API_KEY
  gemini_model: gemini-pro  # Options: gemini-pro, gemini-pro-vision

  # --- Reflection Model (for GEPA Optimization) ---
  # Model used for reflection during GEPA optimization
  # If not set, uses default_model
  # Recommended: Use a strong model (gpt-4, claude-3-opus) for best optimization results
  reflection_model: null  # e.g., "gpt-4", "claude-3-opus", "ollama/llama3.2:70b"

# Default model to use when not specified
# Format: model name (e.g., "gpt-4", "llama2") or provider/model (e.g., "openai/gpt-4", "ollama/llama2")
default_model: null

# ============================================================================
# OPTIMIZATION CONFIGURATION (GEPA)
# ============================================================================
# Configure the GEPA (Genetic Pareto) optimizer
# Used when running: dspy-code optimize

gepa_config:
  # Maximum number of optimization iterations
  max_iterations: 10

  # Population size for genetic algorithm
  # Larger = more diverse but slower
  population_size: 20

  # Mutation rate (0.0 to 1.0)
  # Higher = more exploration, lower = more exploitation
  mutation_rate: 0.1

  # Crossover rate (0.0 to 1.0)
  # Probability of combining two solutions
  crossover_rate: 0.8

  # Evaluation metric for optimization
  # Options: accuracy, f1, precision, recall, custom
  evaluation_metric: accuracy

# ============================================================================
# DSPY OPTIMIZER CONFIGURATION
# ============================================================================
# Additional DSPy optimizer settings (beyond GEPA)

optimizer:
  # Optimizer type
  # Options: BootstrapFewShot, MIPRO, COPRO, SignatureOptimizer
  type: BootstrapFewShot

  # Number of bootstrap examples
  max_bootstrapped_demos: 4

  # Maximum number of labeled examples to use
  max_labeled_demos: 16

  # Teacher model for bootstrapping (if different from default)
  teacher_model: null

  # Metric function for evaluation
  # Can be: accuracy, f1_score, exact_match, or custom function name
  metric: accuracy

  # Number of threads for parallel optimization
  num_threads: 4

# ============================================================================
# EVALUATION METRICS
# ============================================================================
# Configure evaluation metrics for your DSPy programs

evaluation:
  # Default metrics to compute
  metrics:
    - accuracy
    - f1_score
    - precision
    - recall

  # Custom metric functions (Python module paths)
  custom_metrics:
    # Example: my_metrics.custom_accuracy
    # - module.function_name

  # Validation split ratio (0.0 to 1.0)
  validation_split: 0.2

  # Test split ratio (0.0 to 1.0)
  test_split: 0.1

  # Random seed for reproducibility
  random_seed: 42

# ============================================================================
# SIGNATURE CONFIGURATION
# ============================================================================
# Configure DSPy signature generation preferences

signatures:
  # Default signature style
  # Options: concise, detailed, minimal
  style: concise

  # Include type hints in signatures
  include_types: true

  # Include descriptions in signatures
  include_descriptions: true

  # Maximum number of input fields
  max_input_fields: 5

  # Maximum number of output fields
  max_output_fields: 3

# ============================================================================
# REASONING PATTERNS
# ============================================================================
# Configure reasoning pattern preferences

reasoning:
  # Default reasoning pattern
  # Options: predict, chain_of_thought, react, program_of_thought
  default_pattern: chain_of_thought

  # Chain of Thought settings
  cot:
    # Number of reasoning steps
    max_steps: 5

    # Include intermediate reasoning in output
    show_reasoning: true

  # ReAct settings
  react:
    # Maximum number of actions
    max_actions: 10

    # Available tools/actions
    tools: []

  # Program of Thought settings
  pot:
    # Enable code execution
    enable_execution: false

    # Execution timeout (seconds)
    timeout: 30

# ============================================================================
# TEMPLATE PREFERENCES
# ============================================================================
# Customize code generation templates

template_preferences:
  # Code style
  # Options: functional, class-based, modular
  code_style: class-based

  # Include docstrings
  include_docstrings: true

  # Include type hints
  include_type_hints: true

  # Include example usage
  include_examples: true

  # Formatting style
  # Options: black, pep8, google
  formatting_style: black

# ============================================================================
# LOGGING AND DEBUGGING
# ============================================================================
# Configure logging and debugging options

logging:
  # Log level
  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: INFO

  # Log file path (null for console only)
  file: null

  # Include timestamps
  include_timestamps: true

  # Log DSPy internal operations
  log_dspy_internals: false

# ============================================================================
# CACHING
# ============================================================================
# Configure caching for model responses and computations

caching:
  # Enable caching
  enabled: true

  # Cache directory
  cache_dir: .dspy_cache

  # Cache expiration (seconds, null for no expiration)
  expiration: null

  # Maximum cache size (MB)
  max_size: 1000

# ============================================================================
# CODEBASE RAG CONFIGURATION
# ============================================================================
# Configure the codebase knowledge RAG system
# This indexes source code from installed packages to provide better code examples

codebase_rag:
  # Enable/disable codebase RAG
  enabled: true

  # Codebases to index
  # Options: dspy-code, dspy, gepa, mcp
  codebases:
    - dspy-code
    - dspy
    - gepa

  # Cache directory (null for default: .dspy_code/cache/codebase_index in CWD)
  cache_dir: null

  # Maximum cache size in MB
  max_cache_size_mb: 100

  # Days before index is considered stale
  index_refresh_days: 7

  # Use TF-IDF for semantic search (requires scikit-learn)
  use_tfidf: true

  # Patterns to exclude from indexing
  exclude_patterns:
    - tests/
    - test_*.py
    - __pycache__/
    - "*.pyc"
    - .git/
    - .venv/
    - venv/
    - build/
    - dist/
    - "*.egg-info/"
    - node_modules/
    - experimental/
    - examples/

  # Number of code snippets to retrieve
  search_top_k: 5

  # Maximum tokens for code context
  max_context_tokens: 4000

  # Include related code elements
  include_related: true

# ============================================================================
# RETRIEVAL CONFIGURATION
# ============================================================================
# Configure retrieval models for RAG (Retrieval-Augmented Generation)

retrieval:
  # Retrieval model type
  # Options: colbertv2, sentence-transformers, openai-embeddings
  model_type: colbertv2

  # Model name/path
  model_name: colbertv2.0

  # Number of documents to retrieve
  k: 5

  # Vector database
  # Options: faiss, chroma, pinecone, weaviate
  vector_db: faiss

  # Vector database configuration
  vector_db_config:
    # Database path or connection string
    path: .vector_db

    # Embedding dimension
    dimension: 768

# ============================================================================
# MCP (Model Context Protocol) SERVERS
# ============================================================================
# Configure external MCP servers for additional capabilities

mcp_servers:
  # Example: Filesystem server
  # filesystem:
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-filesystem"
  #     - /path/to/allowed/directory
  #   env:
  #     NODE_ENV: production

  # Example: GitHub server
  # github:
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-github"
  #   env:
  #     GITHUB_TOKEN: your_token_here

# ============================================================================
# ADVANCED SETTINGS
# ============================================================================

advanced:
  # Enable experimental features
  experimental_features: false

  # Maximum retries for API calls
  max_retries: 3

  # Timeout for API calls (seconds)
  api_timeout: 60

  # Enable parallel processing
  parallel_processing: true

  # Number of parallel workers
  num_workers: 4

  # Memory limit per worker (MB)
  memory_limit: 2048

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================

datasets:
  # Default dataset format
  # Options: jsonl, csv, parquet, huggingface
  default_format: jsonl

  # Dataset directory
  data_dir: data

  # Training data path
  train_path: null

  # Validation data path
  val_path: null

  # Test data path
  test_path: null

  # Automatic dataset splitting
  auto_split: true

# ============================================================================
# EXPORT CONFIGURATION
# ============================================================================

export:
  # Default export format
  # Options: python, json, package
  default_format: python

  # Include configuration in exports
  include_config: true

  # Include dependencies
  include_dependencies: true

  # Export directory
  export_dir: exports

# ============================================================================
# ENVIRONMENT VARIABLES & API KEYS
# ============================================================================
# BEST PRACTICE: Store API keys in environment variables or .env file
#
# Create a .env file in your project root (automatically loaded):
#   OPENAI_API_KEY=sk-...
#   ANTHROPIC_API_KEY=sk-ant-...
#   GEMINI_API_KEY=...
#
# Or set environment variables:
#   export OPENAI_API_KEY=sk-...
#   export ANTHROPIC_API_KEY=sk-ant-...
#
# The .env file should be in .gitignore to prevent committing secrets!
#
# Priority order:
#   1. Environment variables (highest priority)
#   2. .env file
#   3. Values in this config file (not recommended for API keys)

# ============================================================================
# NOTES
# ============================================================================
# - API keys should be set as environment variables (see above)
# - Use null for optional fields you don't want to configure
# - See documentation for more details: https://dspy-docs.vercel.app/
# - NEVER commit API keys to version control!
# - Add .env to your .gitignore file
