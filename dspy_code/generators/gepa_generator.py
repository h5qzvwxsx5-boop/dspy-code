"""
GEPA optimization code generator for DSPy programs.

Generates complete GEPA optimization scripts with metrics, training data, and configuration.
"""

from typing import Literal


class GEPAGenerator:
    """Generate GEPA optimization code for DSPy programs."""

    def __init__(self):
        self.budget_presets = {
            "light": {
                "description": "Quick experimentation (~6 candidates, 5-10 min)",
                "recommended_for": "Testing optimization setup, quick iterations",
            },
            "medium": {
                "description": "Balanced optimization (~12 candidates, 20-30 min)",
                "recommended_for": "Production use, good balance of quality and time",
            },
            "heavy": {
                "description": "Thorough optimization (~18 candidates, 1-2 hours)",
                "recommended_for": "Maximum performance, final optimization",
            },
        }

    def generate_gepa_script(
        self,
        module_name: str,
        signature_name: str,
        input_fields: list[str],
        output_fields: list[str],
        budget: Literal["light", "medium", "heavy"] = "medium",
        task_type: str = "classification",
    ) -> str:
        """
        Generate complete GEPA optimization script.

        Args:
            module_name: Name of the module to optimize
            signature_name: Name of the signature
            input_fields: List of input field names
            output_fields: List of output field names
            budget: Budget preset (light/medium/heavy)
            task_type: Type of task (classification, generation, qa)

        Returns:
            Complete GEPA optimization script as string
        """

        # Use first output field for metrics
        output_field = output_fields[0] if output_fields else "output"
        input_field = input_fields[0] if input_fields else "input"

        # Generate metric with feedback
        metric_code = self._generate_metric_with_feedback(output_field, task_type)

        # Generate dataset loaders
        dataset_code = self._generate_dataset_loaders(input_fields, output_fields)

        # Generate GEPA configuration
        gepa_config = self._generate_gepa_configuration(budget)

        # Generate optimization execution
        optimization_code = self._generate_optimization_code(module_name, signature_name)

        # Assemble complete script
        script = f'''"""
GEPA Optimization Script for {module_name}

This script uses GEPA (Genetic Pareto) to optimize your DSPy module.
GEPA uses reflection to evolve prompts and improve performance automatically.

Generated by DSPy Code.
"""

import dspy
from dspy.teleprompt import GEPA
import json
from pathlib import Path

# ============================================================================
# 1. METRIC WITH FEEDBACK
# ============================================================================
# GEPA requires a metric that can provide textual feedback to guide optimization

{metric_code}


# ============================================================================
# 2. DATASET LOADERS
# ============================================================================

{dataset_code}


# ============================================================================
# 3. GEPA CONFIGURATION
# ============================================================================

{gepa_config}


# ============================================================================
# 4. OPTIMIZATION EXECUTION
# ============================================================================

{optimization_code}


# ============================================================================
# 5. MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    main()
'''

        return script

    def _generate_metric_with_feedback(self, output_field: str, task_type: str) -> str:
        """Generate metric function with feedback capability."""

        if task_type == "classification":
            return f'''def metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):
    """
    Metric with feedback for GEPA optimization.

    Args:
        gold: Expected output (dspy.Example)
        pred: Predicted output (dspy.Prediction)
        trace: Full program execution trace (optional)
        pred_name: Name of predictor being optimized (optional)
        pred_trace: Trace of specific predictor (optional)

    Returns:
        float: Score (0.0 to 1.0)
        OR
        dict: {{'score': float, 'feedback': str}}
    """
    # Calculate score
    correct = gold.{output_field} == pred.{output_field}
    score = 1.0 if correct else 0.0

    # Provide feedback for incorrect predictions
    if not correct:
        feedback = (
            f"Incorrect prediction. "
            f"Expected: '{{gold.{output_field}}}', "
            f"Got: '{{pred.{output_field}}}'. "
            f"Consider the input context more carefully."
        )
        return {{'score': score, 'feedback': feedback}}

    return score'''

        elif task_type == "generation":
            return f'''def metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):
    """
    Metric with feedback for generation tasks.

    Uses semantic similarity and provides detailed feedback.

    Note: Requires sentence-transformers and scikit-learn:
        pip install sentence-transformers scikit-learn
    """
    try:
        from sentence_transformers import SentenceTransformer
        from sklearn.metrics.pairwise import cosine_similarity
    except ImportError as e:
        raise ImportError(
            "Optional dependencies for semantic similarity not installed!\\n"
            "Install them with: pip install sentence-transformers scikit-learn\\n"
            f"Error: {{e}}"
        )

    # Calculate semantic similarity
    model = SentenceTransformer('all-MiniLM-L6-v2')
    emb1 = model.encode([gold.{output_field}])
    emb2 = model.encode([pred.{output_field}])
    similarity = cosine_similarity(emb1, emb2)[0][0]

    # Provide feedback if similarity is low
    if similarity < 0.8:
        feedback = (
            f"Generated output has low similarity ({{similarity:.2f}}) to expected output. "
            f"Expected key points: {{gold.{output_field}[:100]}}... "
            f"Generated: {{pred.{output_field}[:100]}}... "
            f"Focus on including the main concepts."
        )
        return {{'score': float(similarity), 'feedback': feedback}}

    return float(similarity)'''

        else:  # qa or generic
            return f'''def metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):
    """
    Metric with feedback for QA tasks.

    Checks if answer is contained in prediction.
    """
    # Normalize for comparison
    expected = gold.{output_field}.lower().strip()
    predicted = pred.{output_field}.lower().strip()

    # Check exact match first
    if expected == predicted:
        return 1.0

    # Check if answer is contained
    if expected in predicted:
        return 0.8

    # Check if prediction contains answer
    if predicted in expected:
        score = 0.6
        feedback = (
            f"Partial answer. "
            f"Expected: '{{expected}}', "
            f"Got: '{{predicted}}'. "
            f"Provide more complete information."
        )
        return {{'score': score, 'feedback': feedback}}

    # Completely wrong
    feedback = (
        f"Incorrect answer. "
        f"Expected: '{{expected}}', "
        f"Got: '{{predicted}}'. "
        f"Review the input carefully and provide accurate information."
    )
    return {{'score': 0.0, 'feedback': feedback}}'''

    def _generate_dataset_loaders(self, input_fields: list[str], output_fields: list[str]) -> str:
        """Generate dataset loading code."""

        all_fields = input_fields + output_fields
        fields_str = ", ".join([f'"{f}"' for f in all_fields])

        example_train = {f: f"example {f} 1" for f in all_fields}
        example_val = {f: f"validation {f} 1" for f in all_fields}

        return f'''def load_training_data(path: str = "data/train.json"):
    """Load training dataset for GEPA optimization."""

    dataset_file = Path(path)

    if not dataset_file.exists():
        print(f"âš ï¸  Training data not found: {{path}}")
        print("\\nCreating example training dataset...")

        # Create example training data
        # IMPORTANT: Replace with your actual training examples!
        examples = [
            {example_train},
            {example_train},
            {example_train},
            # Add 20-50 training examples for best results
        ]

        dataset_file.parent.mkdir(parents=True, exist_ok=True)
        with open(dataset_file, 'w') as f:
            json.dump(examples, f, indent=2)

        print(f"âœ“ Created example training data: {{path}}")
        print("  âš ï¸  IMPORTANT: Replace with your actual training examples!")
        print("  Recommended: 20-50 examples for good optimization\\n")

    # Load training data
    with open(dataset_file) as f:
        data = json.load(f)

    # Convert to DSPy examples
    examples = []
    for item in data:
        example = dspy.Example(**item).with_inputs({fields_str})
        examples.append(example)

    print(f"âœ“ Loaded {{len(examples)}} training examples from {{path}}")
    return examples


def load_validation_data(path: str = "data/val.json"):
    """Load validation dataset for tracking optimization progress."""

    dataset_file = Path(path)

    if not dataset_file.exists():
        print(f"âš ï¸  Validation data not found: {{path}}")
        print("\\nCreating example validation dataset...")

        # Create example validation data
        examples = [
            {example_val},
            {example_val},
            {example_val},
            # Add 10-20 validation examples
        ]

        dataset_file.parent.mkdir(parents=True, exist_ok=True)
        with open(dataset_file, 'w') as f:
            json.dump(examples, f, indent=2)

        print(f"âœ“ Created example validation data: {{path}}")
        print("  âš ï¸  IMPORTANT: Replace with your actual validation examples!")
        print("  Recommended: 10-20 examples that match your target distribution\\n")

    # Load validation data
    with open(dataset_file) as f:
        data = json.load(f)

    # Convert to DSPy examples
    examples = []
    for item in data:
        example = dspy.Example(**item).with_inputs({fields_str})
        examples.append(example)

    print(f"âœ“ Loaded {{len(examples)}} validation examples from {{path}}")
    return examples'''

    def _generate_gepa_configuration(self, budget: str) -> str:
        """Generate GEPA configuration code."""

        budget_info = self.budget_presets[budget]

        return f'''def configure_gepa():
    """Configure GEPA optimizer with reflection model."""

    # Load model configuration from dspy_config.yaml
    from dspy_cli.core.config import ConfigManager

    config_manager = ConfigManager()
    config = config_manager.config

    # Configure reflection LM (used by GEPA for reflection)
    # GEPA benefits from a strong reflection model for best results

    # Try to use configured reflection model first
    if config.models.reflection_model:
        reflection_model = config.models.reflection_model
        print(f"Using configured reflection model: {{reflection_model}}")
    # Fallback to default model
    elif config.default_model:
        reflection_model = config.default_model
        print(f"Using default model for reflection: {{reflection_model}}")
    # Fallback to first available model
    elif config.models.ollama_models:
        reflection_model = f"ollama/{{config.models.ollama_models[0]}}"
        print(f"Using Ollama model for reflection: {{reflection_model}}")
    elif config.models.openai_api_key:
        reflection_model = config.models.openai_model
        print(f"Using OpenAI model for reflection: {{reflection_model}}")
    elif config.models.anthropic_api_key:
        reflection_model = config.models.anthropic_model
        print(f"Using Anthropic model for reflection: {{reflection_model}}")
    else:
        # Ultimate fallback
        reflection_model = "gpt-4"
        print("âš ï¸  No model configured, using default: gpt-4")
        print("   Configure a model in dspy_config.yaml for better results")

    # Create reflection LM
    reflection_lm = dspy.LM(
        model=reflection_model,
        temperature=1.0,  # High temperature for creative exploration
        max_tokens=32000 if "gpt-4" in reflection_model else 8000
    )

    # Note about model selection
    print()
    print("ðŸ’¡ Reflection Model Tips:")
    print("   â€¢ Stronger models (GPT-4, Claude-3-Opus) = better optimization")
    print("   â€¢ Local models (Ollama) work but may need more iterations")
    print("   â€¢ You can change the model in dspy_config.yaml")
    print()

    # Create GEPA optimizer
    gepa = GEPA(
        metric=metric_with_feedback,
        auto="{budget}",  # Budget: {budget_info["description"]}
        reflection_lm=reflection_lm,
        track_stats=True,  # Track detailed results
        log_dir="optimization/logs",  # Save logs for resuming
        seed=42  # For reproducibility
    )

    print(f"âœ“ Configured GEPA optimizer")
    print(f"  Budget: {budget} ({budget_info["description"]})")
    print(f"  Reflection model: {{reflection_lm.model}}")
    print(f"  Logs: optimization/logs\\n")

    return gepa'''

    def _generate_optimization_code(self, module_name: str, signature_name: str) -> str:
        """Generate optimization execution code."""

        return f'''def run_optimization(original_module, trainset, valset, gepa):
    """Run GEPA optimization."""

    print("="*60)
    print("Starting GEPA Optimization")
    print("="*60)
    print()

    print("This will:")
    print("  â€¢ Analyze your module's behavior")
    print("  â€¢ Generate improved prompts through reflection")
    print("  â€¢ Track multiple candidate solutions")
    print("  â€¢ Select the best performing variant")
    print()
    print("â±ï¸  This may take some time depending on budget...")
    print()

    # Run optimization
    optimized_module = gepa.compile(
        student=original_module,
        trainset=trainset,
        valset=valset
    )

    print()
    print("="*60)
    print("Optimization Complete!")
    print("="*60)
    print()

    return optimized_module


def show_results(optimized_module):
    """Display optimization results."""

    if not hasattr(optimized_module, 'detailed_results'):
        print("âš ï¸  No detailed results available")
        return

    results = optimized_module.detailed_results

    print("ðŸ“Š Optimization Results:")
    print()
    print(f"  Total candidates explored: {{len(results.candidates)}}")
    print(f"  Best candidate index: {{results.best_idx}}")
    print(f"  Best score: {{results.val_aggregate_scores[results.best_idx]:.4f}}")
    print()

    # Show top 5 candidates
    print("ðŸ† Top 5 Candidates:")
    scores_with_idx = [(i, score) for i, score in enumerate(results.val_aggregate_scores)]
    top_5 = sorted(scores_with_idx, key=lambda x: x[1], reverse=True)[:5]

    for rank, (idx, score) in enumerate(top_5, 1):
        print(f"  {{rank}}. Candidate {{idx}}: {{score:.4f}}")
    print()

    # Show improvement
    baseline_score = results.val_aggregate_scores[0]
    best_score = results.val_aggregate_scores[results.best_idx]
    improvement = ((best_score - baseline_score) / baseline_score * 100) if baseline_score > 0 else 0

    print(f"ðŸ“ˆ Improvement over baseline: {{improvement:+.1f}}%")
    print(f"   Baseline: {{baseline_score:.4f}}")
    print(f"   Optimized: {{best_score:.4f}}")
    print()


def save_optimized_module(optimized_module, path: str = "optimization/optimized_module"):
    """Save the optimized module."""

    output_path = Path(path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Save using DSPy's save function
    dspy.save(optimized_module, str(output_path))

    print(f"ðŸ’¾ Saved optimized module to: {{output_path}}")
    print()


def main():
    """Main optimization workflow."""

    print("\\n" + "="*60)
    print("GEPA Optimization for {module_name}")
    print("="*60 + "\\n")

    # Step 1: Configure DSPy with user's model
    print("Step 1: Configuring DSPy...")

    from dspy_cli.core.config import ConfigManager
    config_manager = ConfigManager()
    config = config_manager.config

    # Use configured default model
    if config.default_model:
        model = config.default_model
    elif config.models.ollama_models:
        model = f"ollama/{{config.models.ollama_models[0]}}"
    elif config.models.openai_api_key:
        model = config.models.openai_model
    else:
        model = "ollama/llama3.2"
        print("âš ï¸  No model configured, using default: ollama/llama3.2")

    lm = dspy.LM(model=model)
    dspy.configure(lm=lm)
    print(f"âœ“ DSPy configured with model: {{model}}\\n")

    # Step 2: Load datasets
    print("Step 2: Loading datasets...")
    trainset = load_training_data()
    valset = load_validation_data()
    print()

    # Step 3: Import and create original module
    print("Step 3: Creating original module...")
    # TODO: Import your module here
    # from your_module import {module_name}
    # original_module = {module_name}()

    print("âš ï¸  Please uncomment the import statement above")
    print("   and import your {module_name} class\\n")

    # Uncomment when you have your module imported:
    # print("âœ“ Module created\\n")

    # Step 4: Configure GEPA
    # print("Step 4: Configuring GEPA optimizer...")
    # gepa = configure_gepa()
    # print()

    # Step 5: Run optimization
    # print("Step 5: Running optimization...")
    # optimized_module = run_optimization(original_module, trainset, valset, gepa)
    # print()

    # Step 6: Show results
    # show_results(optimized_module)

    # Step 7: Save optimized module
    # save_optimized_module(optimized_module)

    # Step 8: Next steps
    print("\\n" + "="*60)
    print("Next Steps:")
    print("="*60 + "\\n")
    print("1. Add your training data to: data/train.json (20-50 examples)")
    print("2. Add your validation data to: data/val.json (10-20 examples)")
    print("3. Uncomment the module import and optimization code above")
    print("4. Run: python optimization/optimize_gepa.py")
    print("5. Load optimized module: dspy.load('optimization/optimized_module')")
    print()
    print("ðŸ’¡ Tips:")
    print("  â€¢ More training data = better optimization")
    print("  â€¢ Validation set should match your target distribution")
    print("  â€¢ Check optimization/logs/ for detailed progress")
    print("  â€¢ Use track_stats=True to analyze all candidates")
    print()'''


def generate_gepa_for_program(
    program_code: str, budget: Literal["light", "medium", "heavy"] = "medium"
) -> str:
    """
    Generate GEPA optimization script for a DSPy program.

    Args:
        program_code: The DSPy program code
        budget: Budget preset (light/medium/heavy)

    Returns:
        Complete GEPA optimization script
    """
    # Parse program to extract module and signature names
    module_name = "YourModule"
    signature_name = "YourSignature"
    input_fields = ["input"]
    output_fields = ["output"]
    task_type = "classification"

    # Try to extract from code
    if "class" in program_code and "Module" in program_code:
        lines = program_code.split("\n")
        for line in lines:
            if "class" in line and "Module" in line:
                parts = line.split()
                if len(parts) >= 2:
                    module_name = parts[1].split("(")[0]
            elif "class" in line and "Signature" in line:
                parts = line.split()
                if len(parts) >= 2:
                    signature_name = parts[1].split("(")[0]
            elif "InputField" in line:
                field_name = line.split("=")[0].strip()
                if field_name and field_name not in input_fields:
                    input_fields = [field_name]
            elif "OutputField" in line:
                field_name = line.split("=")[0].strip()
                if field_name and field_name not in output_fields:
                    output_fields = [field_name]

    # Detect task type
    if "sentiment" in program_code.lower() or "classif" in program_code.lower():
        task_type = "classification"
    elif "question" in program_code.lower() or "answer" in program_code.lower():
        task_type = "qa"
    elif "generat" in program_code.lower() or "summar" in program_code.lower():
        task_type = "generation"

    generator = GEPAGenerator()
    return generator.generate_gepa_script(
        module_name=module_name,
        signature_name=signature_name,
        input_fields=input_fields,
        output_fields=output_fields,
        budget=budget,
        task_type=task_type,
    )
