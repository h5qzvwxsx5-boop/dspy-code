"""
Demo command for DSPy Code.

Provides a complete working example that users can run immediately.
"""

from pathlib import Path

from rich.console import Console
from rich.panel import Panel

from ..ui.animations import ThinkingAnimation
from ..ui.prompts import show_code_panel, show_success_message

console = Console()


def execute_demo(config_manager=None, demo_type="basic"):
    """
    Run a complete working demo of DSPy Code.

    Args:
        config_manager: Configuration manager instance
        demo_type: Type of demo to run ("basic", "mcp", or "complete")

    Shows:
    1. What we're building
    2. Generated signature
    3. Generated module
    4. Usage example
    5. Saves to file

    Returns:
        str: The complete generated code
    """

    if demo_type == "mcp":
        return execute_mcp_demo(config_manager)
    elif demo_type == "complete":
        return execute_complete_demo(config_manager)

    console.print("\n[bold cyan]ðŸŽ¬ DSPy Code Demo - Email Classification[/bold cyan]\n")

    # Step 1: Explain what we're building
    console.print("Let's build an email classifier that categorizes emails into:")
    console.print("  â€¢ [green]Work[/green] - Professional emails")
    console.print("  â€¢ [blue]Personal[/blue] - Personal messages")
    console.print("  â€¢ [red]Spam[/red] - Unwanted emails\n")

    # Step 2: Generate signature
    console.print("[bold]Step 1: Creating the Signature[/bold]")
    console.print("[dim]A signature defines the input/output interface...[/dim]\n")

    with ThinkingAnimation("Generating signature..."):
        import time

        time.sleep(0.5)  # Brief pause for effect

    signature_code = '''import dspy

class EmailClassifier(dspy.Signature):
    """Classify emails into Work, Personal, or Spam categories."""

    email_text = dspy.InputField(desc="The email content to classify")
    category = dspy.OutputField(desc="The email category: Work, Personal, or Spam")'''

    show_code_panel(signature_code, "Generated Signature", "python")
    console.print()

    # Step 3: Generate module
    console.print("[bold]Step 2: Building the Module[/bold]")
    console.print("[dim]A module implements the logic using Chain of Thought reasoning...[/dim]\n")

    with ThinkingAnimation("Building module..."):
        import time

        time.sleep(0.5)

    module_code = '''class EmailClassifierModule(dspy.Module):
    """Email classification module with reasoning."""

    def __init__(self):
        super().__init__()
        self.classifier = dspy.ChainOfThought(EmailClassifier)

    def forward(self, email_text):
        """Classify an email and return the category."""
        result = self.classifier(email_text=email_text)
        return result.category'''

    show_code_panel(module_code, "Generated Module", "python")
    console.print()

    # Step 4: Show usage example
    console.print("[bold]Step 3: How to Use It[/bold]\n")

    usage_code = """# Example usage:
import dspy

# Configure DSPy with your language model (DSPy 3.0+)
lm = dspy.LM(model='openai/gpt-5.1')
dspy.configure(lm=lm)

# Create the classifier
classifier = EmailClassifierModule()

# Classify some emails
result1 = classifier(email_text="Meeting tomorrow at 3pm in conference room B")
print(f"Category: {result1}")  # Output: Work

result2 = classifier(email_text="Hey! Want to grab dinner this weekend?")
print(f"Category: {result2}")  # Output: Personal

result3 = classifier(email_text="CONGRATULATIONS! You won $1,000,000! Click here now!")
print(f"Category: {result3}")  # Output: Spam"""

    show_code_panel(usage_code, "Usage Example", "python")
    console.print()

    # Step 5: Save to file
    console.print("[bold]Step 4: Saving the Code[/bold]\n")

    complete_code = f"{signature_code}\n\n{module_code}\n\n{usage_code}"

    # Determine output directory
    if config_manager:
        output_dir = Path(config_manager.config.output_directory)
    else:
        output_dir = Path("generated")

    output_dir.mkdir(exist_ok=True)
    save_path = output_dir / "demo_email_classifier.py"
    save_path.write_text(complete_code)

    show_success_message(f"Demo code saved to: {save_path}")
    console.print()

    # Step 6: Show next steps
    console.print("[bold green]âœ… Demo Complete![/bold green]\n")

    next_steps = Panel(
        """[bold cyan]What You Can Do Now:[/bold cyan]

1. [yellow]Check out the code:[/yellow]
   cat generated/demo_email_classifier.py

2. [yellow]Try creating your own:[/yellow]
   "Create a signature for sentiment analysis"
   "Build a module for question answering"

3. [yellow]Connect a model for smarter generation:[/yellow]
   /connect ollama llama3.2

4. [yellow]Save your work:[/yellow]
   /save my_classifier.py

5. [yellow]Get help anytime:[/yellow]
   /help

[dim]ðŸ’¡ Tip: The CLI works without a model connection using templates,
but connecting a model gives you much better, context-aware code![/dim]""",
        title="[bold magenta]Next Steps[/bold magenta]",
        border_style="magenta",
        padding=(1, 2),
    )

    console.print(next_steps)
    console.print()

    # Return the generated code so it can be saved with /save
    return complete_code


def execute_mcp_demo(config_manager=None):
    """
    Run an interactive MCP demo showing filesystem integration.

    Demonstrates:
    1. Connecting to MCP filesystem server
    2. Using MCP tools in DSPy programs
    3. Reading/writing files through MCP
    4. Building a document analyzer with MCP

    Returns:
        str: The complete generated code
    """

    console.print(
        "\n[bold cyan]ðŸŽ¬ DSPy Code MCP Demo - Document Analyzer with Filesystem[/bold cyan]\n"
    )

    # Step 1: Explain MCP
    console.print("[bold]What is MCP?[/bold]")
    console.print("MCP (Model Context Protocol) lets DSPy programs interact with external tools.")
    console.print("In this demo, we'll use the [cyan]filesystem MCP server[/cyan] to:")
    console.print("  â€¢ [green]Read documents[/green] from your local filesystem")
    console.print("  â€¢ [blue]Analyze content[/blue] using DSPy")
    console.print("  â€¢ [yellow]Write summaries[/yellow] back to files\n")

    # Step 2: Show MCP setup
    console.print("[bold]Step 1: Setting Up MCP Filesystem Server[/bold]")
    console.print("[dim]First, we configure the MCP server in dspy_config.yaml...[/dim]\n")

    mcp_config = """# In dspy_config.yaml:
mcp_servers:
  filesystem:
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - /path/to/your/documents  # Directory to access
    env:
      NODE_ENV: production"""

    show_code_panel(mcp_config, "MCP Configuration", "yaml")
    console.print()

    # Step 3: Connect to MCP
    console.print("[bold]Step 2: Connecting to MCP Server[/bold]")
    console.print("[dim]Use the /mcp command to connect...[/dim]\n")

    console.print("  [cyan]/mcp connect filesystem[/cyan]")
    console.print("  [dim]â†’ Connects to the filesystem MCP server[/dim]\n")

    console.print("  [cyan]/mcp tools[/cyan]")
    console.print("  [dim]â†’ Shows available tools: read_file, write_file, list_directory[/dim]\n")

    # Step 4: Generate signature with MCP
    console.print("[bold]Step 3: Creating DSPy Signature with MCP Tools[/bold]")
    console.print("[dim]A signature that uses MCP filesystem tools...[/dim]\n")

    with ThinkingAnimation("Generating MCP-enabled signature..."):
        import time

        time.sleep(0.5)

    signature_code = '''import dspy
from dspy_cli.mcp import MCPClientManager

class DocumentAnalyzer(dspy.Signature):
    """Analyze documents from filesystem and generate summaries."""

    file_path = dspy.InputField(desc="Path to the document file")
    summary = dspy.OutputField(desc="A concise summary of the document")
    key_points = dspy.OutputField(desc="List of key points from the document")'''

    show_code_panel(signature_code, "MCP-Enabled Signature", "python")
    console.print()

    # Step 5: Generate module with MCP integration
    console.print("[bold]Step 4: Building Module with MCP Integration[/bold]")
    console.print("[dim]This module reads files using MCP and analyzes them...[/dim]\n")

    with ThinkingAnimation("Building MCP-integrated module..."):
        import time

        time.sleep(0.5)

    module_code = '''class DocumentAnalyzerModule(dspy.Module):
    """Document analyzer using MCP filesystem tools."""

    def __init__(self, mcp_manager):
        super().__init__()
        self.mcp_manager = mcp_manager
        self.analyzer = dspy.ChainOfThought(DocumentAnalyzer)

    async def forward(self, file_path):
        """Read file via MCP, analyze it, and return summary."""
        # Use MCP to read the file
        file_content = await self.mcp_manager.call_tool(
            server_name="filesystem",
            tool_name="read_file",
            arguments={"path": file_path}
        )

        # Analyze the content with DSPy
        result = self.analyzer(
            file_path=file_path,
            document_content=file_content
        )

        # Optionally write summary back via MCP
        summary_path = file_path.replace('.txt', '_summary.txt')
        await self.mcp_manager.call_tool(
            server_name="filesystem",
            tool_name="write_file",
            arguments={
                "path": summary_path,
                "content": f"Summary: {result.summary}\\n\\nKey Points:\\n" +
                          "\\n".join(f"- {point}" for point in result.key_points)
            }
        )

        return result'''

    show_code_panel(module_code, "MCP-Integrated Module", "python")
    console.print()

    # Step 6: Show usage example
    console.print("[bold]Step 5: Using the MCP-Enabled Analyzer[/bold]\n")

    usage_code = """# Example usage:
import dspy
import asyncio
from dspy_cli.mcp import MCPClientManager

# Configure DSPy
lm = dspy.LM(model='openai/gpt-4')
dspy.configure(lm=lm)

# Initialize MCP manager
mcp_manager = MCPClientManager()
await mcp_manager.connect_server("filesystem")

# Create the analyzer
analyzer = DocumentAnalyzerModule(mcp_manager)

# Analyze a document
result = await analyzer(file_path="/documents/report.txt")

print(f"Summary: {result.summary}")
print(f"Key Points: {result.key_points}")
print(f"Summary saved to: /documents/report_summary.txt")

# List available MCP tools
tools = await mcp_manager.list_tools("filesystem")
print(f"Available tools: {[tool.name for tool in tools]}")"""

    show_code_panel(usage_code, "Usage Example with MCP", "python")
    console.print()

    # Step 7: Show MCP commands
    console.print("[bold]Step 6: MCP Commands You Can Use[/bold]\n")

    mcp_commands = Panel(
        """[bold cyan]MCP Commands:[/bold cyan]

[yellow]/mcp connect <server>[/yellow]
  Connect to an MCP server (e.g., filesystem, github)

[yellow]/mcp disconnect <server>[/yellow]
  Disconnect from an MCP server

[yellow]/mcp list[/yellow]
  Show all configured MCP servers

[yellow]/mcp tools [server][/yellow]
  List available tools from MCP servers

[yellow]/mcp resources [server][/yellow]
  List available resources (files, data, etc.)

[yellow]/mcp call <server> <tool> <args>[/yellow]
  Call an MCP tool directly

[dim]ðŸ’¡ MCP servers extend DSPy with external capabilities like
filesystem access, GitHub integration, database queries, and more![/dim]""",
        title="[bold green]MCP Commands[/bold green]",
        border_style="green",
        padding=(1, 2),
    )

    console.print(mcp_commands)
    console.print()

    # Step 8: Save to file
    console.print("[bold]Step 7: Saving the MCP Demo Code[/bold]\n")

    complete_code = f"{signature_code}\n\n{module_code}\n\n{usage_code}"

    # Determine output directory
    if config_manager:
        output_dir = Path(config_manager.config.output_directory)
    else:
        output_dir = Path("generated")

    output_dir.mkdir(exist_ok=True)
    save_path = output_dir / "demo_mcp_document_analyzer.py"
    save_path.write_text(complete_code)

    show_success_message(f"MCP demo code saved to: {save_path}")
    console.print()

    # Step 9: Show next steps
    console.print("[bold green]âœ… MCP Demo Complete![/bold green]\n")

    next_steps = Panel(
        """[bold cyan]Try These MCP Features:[/bold cyan]

1. [yellow]Configure filesystem MCP:[/yellow]
   Edit dspy_config.yaml and add the filesystem server

2. [yellow]Connect to MCP:[/yellow]
   /mcp connect filesystem

3. [yellow]List available tools:[/yellow]
   /mcp tools filesystem

4. [yellow]Try other MCP servers:[/yellow]
   â€¢ GitHub - Access repositories and issues
   â€¢ Brave Search - Web search capabilities
   â€¢ PostgreSQL - Database queries
   â€¢ Slack - Team communication

5. [yellow]Build your own MCP-enabled programs:[/yellow]
   "Create a program that reads files and generates reports"
   "Build a GitHub issue analyzer using MCP"

[dim]ðŸ’¡ Tip: MCP servers are configured in dspy_config.yaml
See dspy_config_example.yaml for more MCP server examples![/dim]""",
        title="[bold magenta]Next Steps with MCP[/bold magenta]",
        border_style="magenta",
        padding=(1, 2),
    )

    console.print(next_steps)
    console.print()

    # Return the generated code
    return complete_code


def execute_complete_demo(config_manager=None):
    """
    Run a complete end-to-end DSPy pipeline demo.

    Demonstrates the full workflow:
    1. Create a DSPy program
    2. Connect to MCP for data access
    3. Execute and test the program
    4. Generate evaluation metrics
    5. Run GEPA optimization
    6. Export the final package

    Returns:
        str: The complete generated code
    """

    console.print("\n[bold cyan]ðŸŽ¬ Complete DSPy Pipeline Demo - End-to-End Workflow[/bold cyan]\n")
    console.print("[bold]This demo shows the entire DSPy development lifecycle:[/bold]")
    console.print("  [green]1.[/green] Program Creation")
    console.print("  [green]2.[/green] MCP Integration")
    console.print("  [green]3.[/green] Execution & Testing")
    console.print("  [green]4.[/green] Evaluation Metrics")
    console.print("  [green]5.[/green] GEPA Optimization")
    console.print("  [green]6.[/green] Package Export\n")

    console.print("â”€" * console.width, style="dim")
    console.print()

    # ========================================================================
    # PART 1: CREATE THE PROGRAM
    # ========================================================================
    console.print("[bold yellow]ðŸ“ PART 1: Creating the DSPy Program[/bold yellow]\n")
    console.print("Let's build a [cyan]Question Answering system[/cyan] that:")
    console.print("  â€¢ Uses MCP to access documents")
    console.print("  â€¢ Retrieves relevant context")
    console.print("  â€¢ Generates accurate answers\n")

    with ThinkingAnimation("Designing the program architecture..."):
        import time

        time.sleep(0.8)

    # Signature
    console.print("[bold]Step 1.1: Defining the Signature[/bold]\n")
    signature_code = '''import dspy

class QuestionAnswering(dspy.Signature):
    """Answer questions using retrieved context from documents."""

    question = dspy.InputField(desc="The question to answer")
    context = dspy.InputField(desc="Retrieved context from documents")
    answer = dspy.OutputField(desc="A concise, accurate answer")
    confidence = dspy.OutputField(desc="Confidence score (0-100)")'''

    show_code_panel(signature_code, "Signature Definition", "python")
    console.print()

    # Module with MCP
    console.print("[bold]Step 1.2: Building the Module with MCP Integration[/bold]\n")

    with ThinkingAnimation("Integrating MCP filesystem access..."):
        time.sleep(0.8)

    module_code = '''class QAModule(dspy.Module):
    """Question answering module with MCP document retrieval."""

    def __init__(self, mcp_manager):
        super().__init__()
        self.mcp_manager = mcp_manager
        self.qa = dspy.ChainOfThought(QuestionAnswering)

    async def retrieve_context(self, question):
        """Retrieve relevant documents using MCP."""
        # List available documents
        docs = await self.mcp_manager.call_tool(
            server_name="filesystem",
            tool_name="list_directory",
            arguments={"path": "/documents"}
        )

        # Read relevant documents (simplified)
        context_parts = []
        for doc in docs[:3]:  # Top 3 documents
            content = await self.mcp_manager.call_tool(
                server_name="filesystem",
                tool_name="read_file",
                arguments={"path": f"/documents/{doc}"}
            )
            context_parts.append(content[:500])  # First 500 chars

        return "\\n\\n".join(context_parts)

    async def forward(self, question):
        """Answer a question using retrieved context."""
        # Retrieve context via MCP
        context = await self.retrieve_context(question)

        # Generate answer with DSPy
        result = self.qa(question=question, context=context)

        return result'''

    show_code_panel(module_code, "QA Module with MCP", "python")
    console.print()

    # ========================================================================
    # PART 2: EXECUTION & TESTING
    # ========================================================================
    console.print("â”€" * console.width, style="dim")
    console.print()
    console.print("[bold yellow]ðŸš€ PART 2: Execution & Testing[/bold yellow]\n")
    console.print("Now let's test the program with sample questions...\n")

    with ThinkingAnimation("Setting up execution environment..."):
        time.sleep(0.8)

    execution_code = """# Initialize and test the QA system
import dspy
import asyncio
from dspy_cli.mcp import MCPClientManager

# Configure DSPy
lm = dspy.LM(model='openai/gpt-4')
dspy.configure(lm=lm)

# Setup MCP
mcp_manager = MCPClientManager()
await mcp_manager.connect_server("filesystem")

# Create QA module
qa_system = QAModule(mcp_manager)

# Test questions
test_questions = [
    "What is the main topic of the documents?",
    "What are the key findings?",
    "What recommendations are provided?"
]

# Run tests
results = []
for question in test_questions:
    result = await qa_system(question=question)
    results.append({
        "question": question,
        "answer": result.answer,
        "confidence": result.confidence
    })
    print(f"Q: {question}")
    print(f"A: {result.answer} (Confidence: {result.confidence}%)\\n")"""

    show_code_panel(execution_code, "Execution & Testing", "python")
    console.print()

    # Show sample output
    sample_output = Panel(
        """[bold cyan]Sample Test Results:[/bold cyan]

[yellow]Q:[/yellow] What is the main topic of the documents?
[green]A:[/green] The documents discuss machine learning optimization techniques.
[dim]Confidence: 85%[/dim]

[yellow]Q:[/yellow] What are the key findings?
[green]A:[/green] GEPA optimization improves model performance by 23% on average.
[dim]Confidence: 92%[/dim]

[yellow]Q:[/yellow] What recommendations are provided?
[green]A:[/green] Use iterative optimization with validation splits for best results.
[dim]Confidence: 88%[/dim]""",
        title="[bold green]âœ“ Execution Results[/bold green]",
        border_style="green",
        padding=(1, 2),
    )
    console.print(sample_output)
    console.print()

    # ========================================================================
    # PART 3: EVALUATION METRICS
    # ========================================================================
    console.print("â”€" * console.width, style="dim")
    console.print()
    console.print("[bold yellow]ðŸ“Š PART 3: Evaluation Metrics[/bold yellow]\n")
    console.print("Let's evaluate the system's performance...\n")

    with ThinkingAnimation("Generating evaluation code..."):
        time.sleep(0.8)

    eval_code = '''# Evaluation setup
from dspy.evaluate import Evaluate

# Define evaluation metric
def answer_accuracy(example, prediction, trace=None):
    """Check if answer is correct and confidence is appropriate."""
    # Exact match
    exact_match = example.answer.lower() == prediction.answer.lower()

    # Semantic similarity (simplified)
    similarity = len(set(example.answer.split()) &
                     set(prediction.answer.split())) / len(set(example.answer.split()))

    # Confidence calibration
    confidence_score = int(prediction.confidence)
    calibrated = (confidence_score > 70 and similarity > 0.7) or \\
                 (confidence_score <= 70 and similarity <= 0.7)

    return exact_match or (similarity > 0.7 and calibrated)

# Load evaluation dataset
eval_dataset = [
    dspy.Example(
        question="What is machine learning?",
        answer="A field of AI that enables systems to learn from data"
    ).with_inputs("question"),
    dspy.Example(
        question="What is GEPA?",
        answer="Genetic Pareto"
    ).with_inputs("question"),
    # ... more examples
]

# Run evaluation
evaluator = Evaluate(
    devset=eval_dataset,
    metric=answer_accuracy,
    num_threads=4,
    display_progress=True
)

score = evaluator(qa_system)
print(f"\\nEvaluation Score: {score:.2%}")
print(f"Passed: {int(score * len(eval_dataset))}/{len(eval_dataset)} examples")'''

    show_code_panel(eval_code, "Evaluation Metrics", "python")
    console.print()

    # Show evaluation results
    eval_results = Panel(
        """[bold cyan]Evaluation Results:[/bold cyan]

[green]âœ“[/green] Accuracy: [bold]87.5%[/bold]
[green]âœ“[/green] Passed: [bold]14/16[/bold] examples
[green]âœ“[/green] Avg Confidence: [bold]86.3%[/bold]
[green]âœ“[/green] Calibration Score: [bold]0.91[/bold]

[yellow]Breakdown by Question Type:[/yellow]
  â€¢ Factual: 93% (13/14)
  â€¢ Analytical: 75% (3/4)
  â€¢ Comparative: 100% (2/2)

[dim]ðŸ’¡ The system performs well on factual questions
but could improve on analytical reasoning.[/dim]""",
        title="[bold green]âœ“ Evaluation Complete[/bold green]",
        border_style="green",
        padding=(1, 2),
    )
    console.print(eval_results)
    console.print()

    # ========================================================================
    # PART 4: GEPA OPTIMIZATION
    # ========================================================================
    console.print("â”€" * console.width, style="dim")
    console.print()
    console.print("[bold yellow]ðŸ§¬ PART 4: GEPA Optimization[/bold yellow]\n")
    console.print("Now let's optimize the system using GEPA...\n")

    with ThinkingAnimation("Setting up GEPA optimization..."):
        time.sleep(0.8)

    gepa_code = """# GEPA Optimization (Genetic Pareto)
from dspy_cli.optimization import OptimizationWorkflowManager, WorkflowState

# Configure GEPA optimization
gepa_config = {
    "max_iterations": 3,
    "population_size": 12,
    "mutation_rate": 0.15,
    "crossover_rate": 0.8,
    "evaluation_metric": "accuracy",
    "selection_strategy": "tournament",
    "elitism": True
}

# Prepare training data
train_dataset = eval_dataset[:12]  # 75% for training
val_dataset = eval_dataset[12:]    # 25% for validation

# Initialize GEPA workflow
workflow = OptimizationWorkflowManager(
    program=qa_system,
    metric=answer_accuracy,
    config=gepa_config
)

# Run GEPA optimization
print("Starting GEPA optimization...")
print(f"Training examples: {len(train_dataset)}")
print(f"Validation examples: {len(val_dataset)}")
print(f"Population size: {gepa_config['population_size']}")
print(f"Max generations: {gepa_config['max_iterations']}\\n")

# Execute genetic evolution
result = workflow.optimize(
    trainset=train_dataset,
    valset=val_dataset
)

# Get optimized program
optimized_qa = result.best_program

# Evaluate optimized version
optimized_score = evaluator(optimized_qa)
improvement = (optimized_score - score) / score * 100

print(f"\\n{'='*60}")
print(f"GEPA Optimization Complete")
print(f"{'='*60}")
print(f"Original Score:  {score:.2%}")
print(f"Optimized Score: {optimized_score:.2%}")
print(f"Improvement:     +{improvement:.1f}%")
print(f"Generations:     {result.generations_completed}")
print(f"Best Generation: {result.best_generation}")
print(f"{'='*60}")"""

    show_code_panel(gepa_code, "GEPA Optimization", "python")
    console.print()

    # Show optimization results
    optimization_results = Panel(
        """[bold cyan]GEPA Optimization Results:[/bold cyan]

[bold]Genetic Evolution Progress:[/bold]
  Generation 1: 87.5% â†’ 89.2% (+1.7%)
    â€¢ Population: 12 candidates
    â€¢ Best: Candidate #7 (enhanced retrieval)

  Generation 2: 89.2% â†’ 91.8% (+2.6%)
    â€¢ Mutation: 15% rate applied
    â€¢ Crossover: Best traits combined
    â€¢ Best: Candidate #3 (multi-step reasoning)

  Generation 3: 91.8% â†’ 93.1% (+1.3%)
    â€¢ Elitism: Top 2 preserved
    â€¢ Selection: Tournament strategy
    â€¢ Best: Candidate #9 (optimized prompts)

[green]Final:[/green] [bold]93.1%[/bold] (+5.6% total improvement)

[bold]Evolved Features:[/bold]
  â€¢ Prompt Strategy: Context-aware retrieval patterns
  â€¢ Reasoning: Multi-step verification with backtracking
  â€¢ Confidence: Calibrated scoring with uncertainty estimation

[bold]Performance Gains:[/bold]
  [green]âœ“[/green] Accuracy: 87.5% â†’ 93.1% (+5.6%)
  [green]âœ“[/green] Passed: 14/16 â†’ 15/16 (+1 example)
  [green]âœ“[/green] Calibration: 0.91 â†’ 0.95 (+4.4%)

[dim]ðŸ’¡ GEPA used genetic algorithms to evolve better prompts
and architectures across 3 generations with 12 candidates each.[/dim]""",
        title="[bold green]âœ“ GEPA Optimization Complete[/bold green]",
        border_style="green",
        padding=(1, 2),
    )
    console.print(optimization_results)
    console.print()

    # ========================================================================
    # PART 5: PACKAGE EXPORT
    # ========================================================================
    console.print("â”€" * console.width, style="dim")
    console.print()
    console.print("[bold yellow]ðŸ“¦ PART 5: Package Export[/bold yellow]\n")
    console.print("Finally, let's export the optimized system as a package...\n")

    with ThinkingAnimation("Building export package..."):
        time.sleep(0.8)

    export_code = """# Export the optimized system
from dspy_cli.export import PackageBuilder, PackageMetadata

# Create package metadata
metadata = PackageMetadata(
    name="qa-system-optimized",
    version="1.0.0",
    description="Optimized QA system with MCP integration",
    author="DSPy Code",
    dependencies=[
        "dspy>=3.0.4",
        "openai>=1.0.0"
    ],
    mcp_servers=["filesystem"]
)

# Build package
builder = PackageBuilder()
package_path = builder.build_package(
    program=optimized_qa,
    metadata=metadata,
    include_evaluation=True,
    include_optimization_history=True,
    output_dir="packages"
)

print(f"\\nâœ“ Package created: {package_path}")
print(f"\\nPackage contents:")
print(f"  â€¢ qa_system.py - Main program")
print(f"  â€¢ evaluation.py - Evaluation metrics")
print(f"  â€¢ optimization_history.json - GEPA results")
print(f"  â€¢ requirements.txt - Dependencies")
print(f"  â€¢ README.md - Documentation")
print(f"  â€¢ mcp_config.yaml - MCP server configuration")"""

    show_code_panel(export_code, "Package Export", "python")
    console.print()

    # Show package structure
    package_structure = Panel(
        """[bold cyan]Exported Package Structure:[/bold cyan]

[yellow]qa-system-optimized/[/yellow]
â”œâ”€â”€ [green]qa_system.py[/green]              # Main QA module
â”œâ”€â”€ [green]evaluation.py[/green]             # Evaluation code
â”œâ”€â”€ [green]optimization_history.json[/green] # GEPA results
â”œâ”€â”€ [green]requirements.txt[/green]          # Dependencies
â”œâ”€â”€ [green]README.md[/green]                 # Documentation
â”œâ”€â”€ [green]mcp_config.yaml[/green]           # MCP configuration
â””â”€â”€ [green]examples/[/green]
    â”œâ”€â”€ basic_usage.py
    â”œâ”€â”€ advanced_usage.py
    â””â”€â”€ sample_data.json

[bold]Package Features:[/bold]
  [green]âœ“[/green] Ready to deploy
  [green]âœ“[/green] Includes all dependencies
  [green]âœ“[/green] MCP configuration included
  [green]âœ“[/green] Evaluation metrics
  [green]âœ“[/green] Optimization history
  [green]âœ“[/green] Usage examples

[dim]ðŸ’¡ Share this package with your team or deploy to production![/dim]""",
        title="[bold green]âœ“ Package Ready[/bold green]",
        border_style="green",
        padding=(1, 2),
    )
    console.print(package_structure)
    console.print()

    # ========================================================================
    # SUMMARY & NEXT STEPS
    # ========================================================================
    console.print("â”€" * console.width, style="dim")
    console.print()
    console.print("[bold green]ðŸŽ‰ Complete Pipeline Demo Finished![/bold green]\n")

    # Save all code
    complete_code = f"""{signature_code}

{module_code}

{execution_code}

{eval_code}

{gepa_code}

{export_code}"""

    if config_manager:
        output_dir = Path(config_manager.config.output_directory)
    else:
        output_dir = Path("generated")

    output_dir.mkdir(exist_ok=True)
    save_path = output_dir / "demo_complete_pipeline.py"
    save_path.write_text(complete_code)

    show_success_message(f"Complete pipeline code saved to: {save_path}")
    console.print()

    # Final summary
    summary = Panel(
        """[bold cyan]What You Just Saw:[/bold cyan]

[bold]1. Program Creation[/bold]
   Created a QA system with MCP document retrieval

[bold]2. MCP Integration[/bold]
   Connected to filesystem server for document access

[bold]3. Execution & Testing[/bold]
   Tested with sample questions, achieved 87.5% accuracy

[bold]4. Evaluation Metrics[/bold]
   Measured performance across different question types

[bold]5. GEPA Optimization[/bold]
   Improved accuracy from 87.5% â†’ 93.1% (+5.6%)

[bold]6. Package Export[/bold]
   Created deployable package with all components

[bold cyan]Commands You Can Use:[/bold cyan]

[yellow]/demo[/yellow]           - Basic email classification
[yellow]/demo mcp[/yellow]       - MCP filesystem integration
[yellow]/demo complete[/yellow]  - This complete pipeline (you just saw it!)

[yellow]/mcp connect[/yellow]    - Connect to MCP servers
[yellow]/run[/yellow]            - Execute your programs
[yellow]/eval[/yellow]           - Generate evaluation code
[yellow]/optimize[/yellow]       - Run GEPA optimization
[yellow]/package[/yellow]        - Export as package

[dim]ðŸ’¡ Try building your own pipeline with these commands![/dim]""",
        title="[bold magenta]Complete DSPy Pipeline[/bold magenta]",
        border_style="magenta",
        padding=(1, 2),
    )

    console.print(summary)
    console.print()

    return complete_code
